+++
title = '医学大模型用知识库榜单'
date = 2023-12-20T19:48:51+08:00
draft = true
+++

| 数据集名称     | 大小                                                         | 出处                                                         | 下载链接                                             |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------------- |
| C4             | 来自互联网上超过3.65亿个域的超过1560亿个token                | T5的训练语料：巨型爬虫数据 Common Crawl 做清洗后得到的语料库 | https://github.com/allenai/allennlp/discussions/5056 |
| ROOTS          | 1.6TB的数据集跨越了59种语言(46种自然语言，13种编程语言)      | BLOOM 的训练语料：62%的文本来自社区选择和记录的语言数据源列表，另外38％的文本来自经过预处理的网络爬取数据集OSCAR, 并通过母语人士的帮助进行了过滤 | https://huggingface.co/bigscience-data               |
| Pile           | 825G的语料                                                   | 22个多样化的高质量子集构成，包括现有的和新构建的子集，许多子集来自学术或专业来 | https://github.com/EleutherAI/the-pile               |
| WuDaoCorpora   | 3TB training data and 1.08T trillion Chinese characters，包含有 822 million Web pages | 采用20多种规则从100TB原始网页数据中清洗得出最终数据集，注重隐私数据信息的去除，源头上避免GPT-3存在的隐私泄露风险；包含教育、科技等50+个行业数据标签，可以支持多领域预训练模型的训练。 | https://data.baai.ac.cn/details/WuDaoCorporaText     |
| THUCNews       | 是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式。 | 中文文本分类数据集：我们在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐。使用THUCTC工具包在此数据集上进行评测，准确率可以达到88.6%。 | https://github.com/thunlp/THUCTC                     |
| CLUECorpus2020 | 通过对[Common Crawl](http://commoncrawl.org/)的中文部分进行语料清洗，最终得到100GB的高质量中文预训练语料。 |                                                              | https://github.com/CLUEbenchmark/CLUECorpus2020      |
| CDial-GPT      | 多轮对话数据                                                 | 本项目提供了一个大规模中文对话数据集，并提供了在此数据集上的中文对话预训练模型（中文GPT模型），更多信息可参考我们的[论文](https://arxiv.org/abs/2008.03946)。 | https://github.com/thu-coai/CDial-GPT                |
| RedPajama-Data | RedPajama 数据的可重现数据接收，1.2万亿                      |                                                              | https://github.com/togethercomputer/RedPajama-Data   |

